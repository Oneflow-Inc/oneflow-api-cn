<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="oneflow.autograd" href="autograd.html" /><link rel="prev" title="oneflow.nn" href="nn.html" />

    <meta name="generator" content="sphinx-3.5.4, furo 2021.04.11.beta34"/>
        <title>oneflow.nn.functional - OneFlow documentation</title>
      <link rel="stylesheet" href="_static/styles/furo.css?digest=59ab60ac09ea94ccfe6deddff6d715cce948a6fc">
    <link rel="stylesheet" href="_static/pygments.css">
    <link media="(prefers-color-scheme: dark)" rel="stylesheet" href="_static/pygments_dark.css">
    


<style>
  :root {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }

  /* For allowing end-user-specific overrides */
  .override-light {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  .override-dark {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
</style><link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" href="_static/styles/furo-extensions.css?digest=d391b54134226e4196576da3bdb6dddb7e05ba2b"></head>
  <body dir="">
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke-width="1.5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z"/>
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">OneFlow  documentation</div></a>
    </div>
    <div class="header-right">
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">OneFlow  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html">
  <input class="sidebar-search" placeholder=Search name="q">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
</ul>
<p class="caption"><span class="caption-text">OneFlow Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="oneflow.html">oneflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">oneflow.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">oneflow.nn</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">oneflow.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">oneflow.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">oneflow.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">oneflow.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">oneflow.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">oneflow.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">oneflow.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="module.html">oneflow.nn.Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph.html">oneflow.nn.Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="image.html">oneflow.nn.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">oneflow.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="env.html">oneflow.env</a></li>
<li class="toctree-l1"><a class="reference internal" href="comm.html">oneflow.comm</a></li>
<li class="toctree-l1"><a class="reference internal" href="one_embedding.html">oneflow.one_embedding</a></li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <main class="main">
    <div class="content">
      <article role="main">
        <label class="toc-overlay-icon toc-content-icon" for="__toc">
          <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
        </label>
        <div class="section" id="oneflow-nn-functional">
<h1>oneflow.nn.functional<a class="headerlink" href="#oneflow-nn-functional" title="Permalink to this headline">¶</a></h1>
<div class="section" id="functional-operations-for-neural-networks">
<h2>Functional operations for neural networks<a class="headerlink" href="#functional-operations-for-neural-networks" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="oneflow.nn.functional.conv1d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">conv1d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>文档引用自: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.conv1d.html?highlight=conv1d">https://pytorch.org/docs/stable/generated/torch.nn.functional.conv1d.html?highlight=conv1d</a></p>
<p>对由多个输入平面组成的输入信号应用一维卷积。</p>
<p>请参阅: <a class="reference internal" href="nn.html#oneflow.nn.Conv1d" title="oneflow.nn.Conv1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv1d</span></code></a> 获取有关详细信息和输出形状。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong>: 形状的量化输入张量: <span class="math notranslate nohighlight">\((\text{minibatch} , \text{in_channels} , iW)\)</span></p></li>
<li><p><strong>weight</strong>: 形状的量化滤波器: <span class="math notranslate nohighlight">\((\text{out_channels} , \frac{\text{in_channels}}{\text{groups}} , iW)\)</span></p></li>
<li><p><strong>bias</strong>: 非量化的形状的偏置张量: <span class="math notranslate nohighlight">\((\text{out_channels})\)</span> 。张量类型必须为 <cite>flow.float</cite> 。</p></li>
<li><p><strong>stride</strong>: 卷积核的步长。可以是单个数字或元组 <cite>(sW,)</cite> 。 默认值: 1</p></li>
<li><p><strong>padding</strong>: 输入两侧的隐式填充。可以是单个数字或元组 <cite>(padW,)</cite> 。 默认值: 0</p></li>
<li><p><strong>dilation</strong>: 内核元素之间的间距。可以是单个数字或元组 <cite>(dW,)</cite> 。 默认值: 1</p></li>
<li><p><strong>groups</strong>: 将输入分成组: <span class="math notranslate nohighlight">\(\text{in_channels}\)</span> 应该可以被组数整除。默认值: 1</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow.nn</span> <span class="kn">as</span> <span class="nn">nn</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filters</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dilation</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channel_pos</span><span class="o">=</span><span class="s2">"channels_first"</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.conv2d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">conv2d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>文档引用自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html?highlight=conv2d">https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html?highlight=conv2d</a></p>
<p>对由多个输入平面组成的输入信号应用二维卷积。</p>
<p>请参阅 <a class="reference internal" href="nn.html#oneflow.nn.Conv2d" title="oneflow.nn.Conv2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv2d</span></code></a> 获取有关详细信息和输出形状。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> - 形状为 <span class="math notranslate nohighlight">\((\text{minibatch} , \text{in_channels} , iH , iW)\)</span> 的量化输入张量</p></li>
<li><p><strong>weight</strong> - 形状为 <span class="math notranslate nohighlight">\((\text{out_channels} , \frac{\text{in_channels}}{\text{groups}} , kH , kW)\)</span> 的量化滤波器</p></li>
<li><p><strong>bias</strong> - 形状为 <span class="math notranslate nohighlight">\((\text{out_channels})\)</span> 的非量化偏置张量，其类型必须为 <cite>flow.float</cite>。</p></li>
<li><p><strong>stride</strong> - 卷积核的步长。可以是单个数字或元组 <cite>(sH, sW)</cite>， 默认值：1。</p></li>
<li><p><strong>padding</strong> - 输入两侧的隐式填充。可以是单个数字或元组 <cite>(padH, padW)</cite>，默认值：0。</p></li>
<li><p><strong>dilation</strong> - 内核元素之间的间距。可以是单个数字或元组 <cite>(dH, dW)</cite>，默认值：1。</p></li>
<li><p><strong>groups</strong> - 将输入分成应该可以被组数整除的 <span class="math notranslate nohighlight">\(\text{in_channels}\)</span>，默认值：1。</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.conv3d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">conv3d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.conv3d" title="Permalink to this definition">¶</a></dt>
<dd><p>文档引用自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.conv3d.html?highlight=conv3d">https://pytorch.org/docs/stable/generated/torch.nn.functional.conv3d.html?highlight=conv3d</a></p>
<p>对由多个输入平面组成的输入信号应用三维卷积。</p>
<p>请参阅 <a class="reference internal" href="nn.html#oneflow.nn.Conv3d" title="oneflow.nn.Conv3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code></a> 获取有关详细信息和输出形状。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> - 形状为 <span class="math notranslate nohighlight">\((\text{minibatch} , \text{in_channels} , iD , iH , iW)\)</span> 的量化输入张量</p></li>
<li><p><strong>weight</strong> - 形状为 <span class="math notranslate nohighlight">\((\text{out_channels} , \frac{\text{in_channels}}{\text{groups}} , kD , kH , kW)\)</span> 的量化滤波器</p></li>
<li><p><strong>bias</strong> - 形状为 <span class="math notranslate nohighlight">\((\text{out_channels})\)</span> 的化偏置张量，其类型必须为 <cite>flow.float</cite>。</p></li>
<li><p><strong>stride</strong> - 卷积核的步长。可以是单个数字或元组 <cite>(sD, sH, sW)</cite>， 默认值：1。</p></li>
<li><p><strong>padding</strong> - 输入两侧的隐式填充。可以是单个数字或元组 <cite>(padD, padH, padW)</cite>，默认值：0。</p></li>
<li><p><strong>dilation</strong> - 内核元素之间的间距。可以是单个数字或元组 <cite>(dD, dH, dW)</cite>，默认值：1。</p></li>
<li><p><strong>groups</strong> - 将输入分成应该可以被组数整除的 <span class="math notranslate nohighlight">\(\text{in_channels}\)</span>，默认值：1。</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.conv_transpose1d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">conv_transpose1d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.conv_transpose1d" title="Permalink to this definition">¶</a></dt>
<dd><p>此文档参考自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.conv_transpose1d.html">https://pytorch.org/docs/stable/generated/torch.nn.functional.conv_transpose1d.html</a></p>
<p>对多个输入面信号应用一个 1D 转置卷积算子，有时也被称为“反卷积”。</p>
<p>关于输出形状和更多细节，见 <a class="reference internal" href="nn.html#oneflow.nn.ConvTranspose1d" title="oneflow.nn.ConvTranspose1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose1d</span></code></a></p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong>: 形状为 <span class="math notranslate nohighlight">\((\text{minibatch} , \text{in_channels} , iW)\)</span> 的输入张量</p></li>
<li><p><strong>weight</strong>: 形状为 <span class="math notranslate nohighlight">\((\text{in_channels} , \frac{\text{out_channels}}{\text{groups}} , kW)\)</span> 的过滤层</p></li>
<li><p><strong>bias</strong>: 可选的形状为 <span class="math notranslate nohighlight">\((\text{out_channels})\)</span> 的过滤 bias 。默认值：None</p></li>
<li><p><strong>stride</strong>: 卷积核的步长。可以是单个数字，也可以是一个 <cite>(sW,)</cite> 元组。默认值：1</p></li>
<li><p><strong>padding</strong>: <cite>dilation * (kernel_size - 1) - padding</cite> 零填充将会被加至所有输入维度的两侧。可以是单个数字，也可以是一个 <cite>(padW,)</cite> 元组。默认值：0</p></li>
<li><p><strong>output_padding</strong>: 被加至输出形状的所有维度一侧的额外尺寸。可以是单个数字，也可以是一个 <cite>(out_padW)</cite> 元组。默认值：0</p></li>
<li><p><strong>groups</strong>: 将输入切分成组， <span class="math notranslate nohighlight">\(\text{in_channels}\)</span> 需要被组的数量整除。默认值：1</p></li>
<li><p><strong>dilation</strong>: 内核元素的区间。可以是单个数字，也可以是一个 <cite>(dW,)</cite> 元组。默认值：1</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv_transpose1d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.conv_transpose2d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">conv_transpose2d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.conv_transpose2d" title="Permalink to this definition">¶</a></dt>
<dd><p>此文档参考自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.conv_transpose2d.html">https://pytorch.org/docs/stable/generated/torch.nn.functional.conv_transpose2d.html</a></p>
<p>对多个输入面信号应用一个 2D 转置卷积算子，有时也被称为 <code class="docutils literal notranslate"><span class="pre">反卷积</span></code>。</p>
<p>关于输出形状和更多细节，见 <a class="reference internal" href="nn.html#oneflow.nn.ConvTranspose2d" title="oneflow.nn.ConvTranspose2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code></a></p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong>: 形状为 <span class="math notranslate nohighlight">\((\text{minibatch} , \text{in_channels} , iH , iW)\)</span> 的输入张量</p></li>
<li><p><strong>weight</strong>: 形状为 <span class="math notranslate nohighlight">\((\text{in_channels} , \frac{\text{out_channels}}{\text{groups}} , kH , kW)\)</span> 的过滤层</p></li>
<li><p><strong>bias</strong>: 可选的形状为 <span class="math notranslate nohighlight">\((\text{out_channels})\)</span> 的过滤 bias 。默认值：None</p></li>
<li><p><strong>stride</strong>: 卷积核的步长。可以是单个数字，也可以是一个  <cite>(sH, sW)</cite> 元组。默认值：1</p></li>
<li><p><strong>padding</strong>: <cite>dilation * (kernel_size - 1) - padding</cite> 零填充将会被加至所有输入维度的两侧。可以是单个数字，也可以是一个  <cite>(padH, padW)</cite> 元组。默认值：0</p></li>
<li><p><strong>output_padding</strong>: 被加至输出形状的所有维度一侧的额外尺寸。可以是单个数字，也可以是一个 <cite>(out_padH, out_padW)</cite> 元组。默认值：0</p></li>
<li><p><strong>groups</strong>: 将输入切分成组， <span class="math notranslate nohighlight">\(\text{in_channels}\)</span> 需要被组的数量整除。默认值：1</p></li>
<li><p><strong>dilation</strong>: 内核元素的区间。可以是单个数字，也可以是一个 <cite>(dH, dW)</cite> 元组。默认值：1</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv_transpose2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.conv_transpose3d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">conv_transpose3d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.conv_transpose3d" title="Permalink to this definition">¶</a></dt>
<dd><p>此文档参考自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.conv_transpose3d.html">https://pytorch.org/docs/stable/generated/torch.nn.functional.conv_transpose3d.html</a></p>
<p>对多个输入面信号应用一个 3D 转置卷积算子，有时也被称为 <code class="docutils literal notranslate"><span class="pre">反卷积</span></code>。</p>
<p>关于输出形状和更多细节，见 <a class="reference internal" href="nn.html#oneflow.nn.ConvTranspose3d" title="oneflow.nn.ConvTranspose3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose3d</span></code></a></p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong>: 形状为 <span class="math notranslate nohighlight">\((\text{minibatch} , \text{in_channels} , iT , iH , iW)\)</span> 的输入张量</p></li>
<li><p><strong>weight</strong>: 形状为 <span class="math notranslate nohighlight">\((\text{in_channels} , \frac{\text{out_channels}}{\text{groups}} , kT , kH , kW)\)</span> 的过滤层</p></li>
<li><p><strong>bias</strong>: 可选的形状为 <span class="math notranslate nohighlight">\((\text{out_channels})\)</span> 的过滤 bias 。默认值：None</p></li>
<li><p><strong>stride</strong>: 卷积核的步长。可以是单个数字，也可以是一个  <cite>(sD, sH, sW)</cite> 元组。默认值：1</p></li>
<li><p><strong>padding</strong>: <cite>dilation * (kernel_size - 1) - padding</cite> 零填充将会被加至所有输入维度的两侧。可以是单个数字，也可以是一个  <cite>(padT, padH, padW)</cite> 元组。默认值：0</p></li>
<li><p><strong>output_padding</strong>: 被加至输出形状的所有维度一侧的额外尺寸。可以是单个数字，也可以是一个 <cite>(out_padT, out_padH, out_padW)</cite> 元组。默认值：0</p></li>
<li><p><strong>groups</strong>: 将输入切分成组， <span class="math notranslate nohighlight">\(\text{in_channels}\)</span> 需要被组的数量整除。默认值：1</p></li>
<li><p><strong>dilation</strong>: 内核元素的区间。可以是单个数字，也可以是一个 <cite>(dT, dH, dW)</cite> 元组。默认值：1</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv_transpose3d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.adaptive_avg_pool1d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">adaptive_avg_pool1d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.adaptive_avg_pool1d" title="Permalink to this definition">¶</a></dt>
<dd><p>在单个由几个输入平面组成的输入信号上应用 1D 自适应平均池化。</p>
<p>更多细节和输出的形状请参考 <a class="reference internal" href="nn.html#oneflow.nn.AdaptiveAvgPool1d" title="oneflow.nn.AdaptiveAvgPool1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdaptiveAvgPool1d</span></code></a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> - 输入张量。</p></li>
<li><p><strong>output_size</strong> - 目标输出大小（单个整数）。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span> <span class="mf">0.0558</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6875</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6544</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6226</span><span class="p">,</span>  <span class="mf">0.1018</span><span class="p">,</span>  <span class="mf">0.0502</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2538</span><span class="p">,</span> <span class="mf">0.1491</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
<span class="go">tensor([[[-0.3158, -1.1385,  0.0760, -0.5524]]], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.adaptive_avg_pool2d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">adaptive_avg_pool2d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.adaptive_avg_pool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>在单个由几个输入平面组成的输入信号上应用 2D 自适应平均池化。</p>
<p>更多细节和输出的形状请参考 <a class="reference internal" href="nn.html#oneflow.nn.AdaptiveAvgPool2d" title="oneflow.nn.AdaptiveAvgPool2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdaptiveAvgPool2d</span></code></a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> - 输入张量。</p></li>
<li><p><strong>output_size</strong> - 目标输出大小（单个整数或二整数元组）。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span> <span class="mf">0.1004</span><span class="p">,</span>  <span class="mf">0.0488</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0515</span><span class="p">,</span>  <span class="mf">0.9466</span><span class="p">],[</span> <span class="mf">0.4538</span><span class="p">,</span>  <span class="mf">0.2361</span><span class="p">,</span>  <span class="mf">1.3437</span><span class="p">,</span>  <span class="mf">0.398</span> <span class="p">],[</span> <span class="mf">0.0558</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6875</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6544</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6226</span><span class="p">],[</span> <span class="mf">0.1018</span><span class="p">,</span>  <span class="mf">0.0502</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2538</span><span class="p">,</span>  <span class="mf">0.1491</span><span class="p">]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.adaptive_avg_pool3d">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">adaptive_avg_pool3d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.adaptive_avg_pool3d" title="Permalink to this definition">¶</a></dt>
<dd><p>在单个由几个输入平面组成的输入信号上应用 3D 自适应平均池化。</p>
<p>更多细节和输出的形状请参考 <a class="reference internal" href="nn.html#oneflow.nn.AdaptiveAvgPool3d" title="oneflow.nn.AdaptiveAvgPool3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdaptiveAvgPool3d</span></code></a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> - 输入张量。</p></li>
<li><p><strong>output_size</strong> - 目标输出大小（单个整数或三整数元组）。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool3d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.relu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">relu</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.relu" title="Permalink to this definition">¶</a></dt>
<dd><p>对 <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> 逐元素应用 ReLU 函数(Rectified Linear Unit，线性整流函数)。更多信息请参考 <a class="reference internal" href="nn.html#oneflow.nn.ReLU" title="oneflow.nn.ReLU"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReLU</span></code></a> 。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor)</p></li>
<li><p><strong>inplace</strong> (Bool): 如果为 <code class="docutils literal notranslate"><span class="pre">True</span></code> ，则以原地算法执行此算子。默认为 <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span>
<span class="go">tensor([1., 0., 3.], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.hardsigmoid">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">hardsigmoid</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.hardsigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素应用以下函数:</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\begin{split}\text{Hardsigmoid}(x) = \begin{cases}
    0 &amp; \text{if~} x \le -3, \\
    1 &amp; \text{if~} x \ge +3, \\
    x / 6 + 1 / 2 &amp; \text{otherwise}
\end{cases}\end{split}\]</div></div>
<p>更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.Hardsigmoid" title="oneflow.nn.Hardsigmoid"><code class="xref py py-class docutils literal notranslate"><span class="pre">Hardsigmoid</span></code></a>。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.hardshrink">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">hardshrink</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.hardshrink" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.hardswish">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">hardswish</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.hardswish" title="Permalink to this definition">¶</a></dt>
<dd><p>按照论文 <a class="reference external" href="https://arxiv.org/abs/1905.02244">Searching for MobileNetV3</a> 中的描述，应用 hardswish 函数。</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\begin{split}\text{Hardswish}(x) = \begin{cases}
    0 &amp; \text{if~} x \le -3, \\
    x &amp; \text{if~} x \ge +3, \\
    x \cdot (x + 3) /6 &amp; \text{otherwise}
\end{cases}\end{split}\]</div></div>
<p>更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.Hardswish" title="oneflow.nn.Hardswish"><code class="xref py py-class docutils literal notranslate"><span class="pre">Hardswish</span></code></a>。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.hardtanh">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">hardtanh</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1.</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.hardtanh" title="Permalink to this definition">¶</a></dt>
<dd><p>应用 HardTanh 函数。
更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.Hardtanh" title="oneflow.nn.Hardtanh"><code class="xref py py-class docutils literal notranslate"><span class="pre">Hardtanh</span></code></a>。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.normalize">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">normalize</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>对指定维度的输入进行 <span class="math notranslate nohighlight">\(L_p\)</span> 规范化处理。</p>
<p>对于大小为 <span class="math notranslate nohighlight">\((n_0, ..., n_{dim}, ..., n_k)\)</span> 的 <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> 张量，每一个 <span class="math notranslate nohighlight">\(n_{dim}\)</span> 维向量 <span class="math notranslate nohighlight">\(v\)</span> 沿维度 <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code> 被转换为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[v = \frac{v}{\max(\lVert v \rVert_p, \epsilon)}.\]</div></div>
<p>在默认参数下，它使用沿维度 <span class="math notranslate nohighlight">\(1\)</span> 的向量上的欧几里得准则进行归一化。</p>
<p>但要注意，当 <cite>input.shape[dim] = 1</cite> 时，输入张量的梯度计算在不同的框架上有不同的结果。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> (oneflow.Tensor)- 任何形状的输入张量。</p></li>
<li><p><strong>p</strong> (float)- 规范表述中的指数值，默认值：2。</p></li>
<li><p><strong>dim</strong> (int)- 要缩小的尺寸，默认值：1。</p></li>
<li><p><strong>eps</strong> (float)- 以避免被零除的极小值，默认值：1e-12。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[0.3162, 0.4472],</span>
<span class="go">        [0.9487, 0.8944]], dtype=oneflow.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[0.4472, 0.8944],</span>
<span class="go">        [0.6000, 0.8000]], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.layer_norm">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">layer_norm</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.layer_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>对最后一定数量的维度应用图层标准化。</p>
<p>更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.LayerNorm" title="oneflow.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a>。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.leaky_relu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">leaky_relu</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Float</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.leaky_relu" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素应用以下函数:</p>
<p><span class="math notranslate nohighlight">\(\text{LeakyReLU}(x) = \max(0, x) + \text{negative_slope} * \min(0, x)\)</span></p>
<p>更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.LeakyReLU" title="oneflow.nn.LeakyReLU"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeakyReLU</span></code></a>。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.elu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">elu</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Float</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.elu" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素应用以下函数:</p>
<p><span class="math notranslate nohighlight">\(\text{ELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x) - 1))\)</span></p>
<p>更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.ELU" title="oneflow.nn.ELU"><code class="xref py py-class docutils literal notranslate"><span class="pre">ELU</span></code></a>。</p>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([-0.3935,  0.0000,  0.5000], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.celu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">celu</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.celu" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素地应用如下等式：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\text{CELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x/\alpha) - 1))\]</div></div>
<p>更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.CELU" title="oneflow.nn.CELU"><code class="xref py py-class docutils literal notranslate"><span class="pre">CELU</span></code></a> 。</p>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">celu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([-0.3161,  0.0000,  0.5000], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.selu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">selu</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.selu" title="Permalink to this definition">¶</a></dt>
<dd><p>应用以下 element-wise 公式：</p>
<p><span class="math notranslate nohighlight">\(\text{SELU}(x) = scale * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1)))\)</span> ,
<span class="math notranslate nohighlight">\(\alpha=1.6732632423543772848170429916717\)</span> ,
<span class="math notranslate nohighlight">\(scale=1.0507009873554804934193349852946\)</span></p>
<p>更多信息请参考 <a class="reference internal" href="nn.html#oneflow.nn.SELU" title="oneflow.nn.SELU"><code class="xref py py-class docutils literal notranslate"><span class="pre">SELU</span></code></a> 。</p>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">selu</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([1.0507, 2.1014, 3.1521], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.sigmoid">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">sigmoid</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>应用以下 element-wise 公式：
<span class="math notranslate nohighlight">\(\text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}\)</span></p>
<p>更多信息请参考 <a class="reference internal" href="nn.html#oneflow.nn.Sigmoid" title="oneflow.nn.Sigmoid"><code class="xref py py-class docutils literal notranslate"><span class="pre">Sigmoid</span></code></a> 。</p>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.81733328</span><span class="p">,</span> <span class="mf">0.43621480</span><span class="p">,</span> <span class="mf">0.10351428</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([0.6937, 0.6074, 0.5259], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.pad">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">pad</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.pad" title="Permalink to this definition">¶</a></dt>
<dd><p>填充张量。</p>
<dl class="simple">
<dt>填充大小：</dt><dd><p>对输入张量某些维度的填充大小的描述从最后一个维度开始，然后是前一个维度，依此类推。<code class="docutils literal notranslate"><span class="pre">input</span></code> 的维度将被填充为  <span class="math notranslate nohighlight">\(\left\lfloor\frac{\text{len(pad)}}{2}\right\rfloor\)</span> 。
例如，若只对输入张量的最后一个维度进行填充，那么 <a class="reference internal" href="#oneflow.nn.functional.pad" title="oneflow.nn.functional.pad"><code class="xref py py-attr docutils literal notranslate"><span class="pre">pad</span></code></a> 的参数应为 <span class="math notranslate nohighlight">\((\text{padding_left}, \text{padding_right})\)</span> ；
若填充输入张量的最后两个维度，则参数变成 <span class="math notranslate nohighlight">\((\text{padding_left}, \text{padding_right},\)</span> <span class="math notranslate nohighlight">\(\text{padding_top}, \text{padding_bottom})\)</span>；
填充最后 3 个维度时，参数将为 <span class="math notranslate nohighlight">\((\text{padding_left}, \text{padding_right},\)</span> <span class="math notranslate nohighlight">\(\text{padding_top}, \text{padding_bottom}\)</span> <span class="math notranslate nohighlight">\(\text{padding_front}, \text{padding_back})\)</span>。</p>
</dd>
<dt>填充模式：</dt><dd><p>参考 <a class="reference internal" href="nn.html#oneflow.nn.ConstantPad2d" title="oneflow.nn.ConstantPad2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">oneflow.nn.ConstantPad2d</span></code></a>， <a class="reference internal" href="nn.html#oneflow.nn.ReflectionPad2d" title="oneflow.nn.ReflectionPad2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">oneflow.nn.ReflectionPad2d</span></code></a>，以及 <a class="reference internal" href="nn.html#oneflow.nn.ReplicationPad2d" title="oneflow.nn.ReplicationPad2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">oneflow.nn.ReplicationPad2d</span></code></a>
可以得到每个填充模式是如何工作的具体例子。对任意的尺寸实现恒定的填充。复制填充的引入是为了填充 5D 输入张量的最后 3 维，
或 4D 输入张量的最后 2 维，或 3D 输入张量的最后一维。反射填充仅用于填充 4D 输入张量的最后两个维度，或 3D 输入张量的最后一个维度。</p>
</dd>
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor)- N 维张量。</p></li>
<li><p><strong>pad</strong> (tuple)- m 个元素的元组，其中 <span class="math notranslate nohighlight">\(\frac{m}{2} \leq\)</span> 输入维度以及 <span class="math notranslate nohighlight">\(m\)</span> 为偶数。</p></li>
<li><p><strong>mode</strong> - <code class="docutils literal notranslate"><span class="pre">'constant'</span></code>， <code class="docutils literal notranslate"><span class="pre">'reflect'</span></code>， <code class="docutils literal notranslate"><span class="pre">'replicate'</span></code> 或者 <code class="docutils literal notranslate"><span class="pre">'circular'</span></code>。默认值： <code class="docutils literal notranslate"><span class="pre">'constant'</span></code>。</p></li>
<li><p><strong>value</strong> - 填充值为 <code class="docutils literal notranslate"><span class="pre">'constant'</span></code> 的填充。默认值： <code class="docutils literal notranslate"><span class="pre">0</span></code>。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">pad</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s2">"replicate"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">shape</span>
<span class="go">oneflow.Size([1, 2, 5, 7])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span>
<span class="go">tensor([[[[ 0.,  0.,  0.,  1.,  2.,  2.,  2.],</span>
<span class="go">          [ 0.,  0.,  0.,  1.,  2.,  2.,  2.],</span>
<span class="go">          [ 3.,  3.,  3.,  4.,  5.,  5.,  5.],</span>
<span class="go">          [ 6.,  6.,  6.,  7.,  8.,  8.,  8.],</span>
<span class="go">          [ 6.,  6.,  6.,  7.,  8.,  8.,  8.]],</span>

<span class="go">         [[ 9.,  9.,  9., 10., 11., 11., 11.],</span>
<span class="go">          [ 9.,  9.,  9., 10., 11., 11., 11.],</span>
<span class="go">          [12., 12., 12., 13., 14., 14., 14.],</span>
<span class="go">          [15., 15., 15., 16., 17., 17., 17.],</span>
<span class="go">          [15., 15., 15., 16., 17., 17., 17.]]]], dtype=oneflow.float32)</span>
</pre></div>
</div>
<p>参考 <a class="reference internal" href="nn.html#oneflow.nn.ConstantPad2d" title="oneflow.nn.ConstantPad2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">oneflow.nn.ConstantPad2d</span></code></a>, <a class="reference internal" href="nn.html#oneflow.nn.ReflectionPad2d" title="oneflow.nn.ReflectionPad2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">oneflow.nn.ReflectionPad2d</span></code></a> 和 <a class="reference internal" href="nn.html#oneflow.nn.ReplicationPad2d" title="oneflow.nn.ReplicationPad2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">oneflow.nn.ReplicationPad2d</span></code></a> ，可以得到每个填充模式是如何工作的具体例子。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.prelu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">prelu</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.prelu" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素应用以下函数:</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[prelu(x) = max(0,x) + alpha * min(0,x)\]</div></div>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="o">&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]]]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>
<span class="o">&gt;</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">prelu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">3.0000</span><span class="p">,</span>  <span class="mf">4.0000</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">oneflow</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">prelu_backward</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.PReLU" title="oneflow.nn.PReLU"><code class="xref py py-class docutils literal notranslate"><span class="pre">PReLU</span></code></a> 。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.logsigmoid">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">logsigmoid</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.logsigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素应用函数:</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\text{logsigmoid}(x) = \log\left(\frac{ 1 }{ 1 + \exp(-x)}\right)\]</div></div>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([-0.9741, -0.6931, -0.4741], dtype=oneflow.float32)</span>
</pre></div>
</div>
<p>更多细节请参考 <a class="reference internal" href="nn.html#oneflow.nn.LogSigmoid" title="oneflow.nn.LogSigmoid"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogSigmoid</span></code></a> 。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.log_softmax">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">log_softmax</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>LogSoftmax 的公式为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right) = x_i - \log({ \sum_j \exp(x_j)})\]</div></div>
<p>参考 <a class="reference internal" href="nn.html#oneflow.nn.LogSoftmax" title="oneflow.nn.LogSoftmax"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogSoftmax</span></code></a> 获得更多细节。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.gelu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">gelu</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.gelu" title="Permalink to this definition">¶</a></dt>
<dd><p>Gelu 激活算子，其公式为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[out = 0.5 * x * (1 + tanh(\sqrt{\frac{2}{\pi}} * (x + 0.044715x^{3})))\]</div></div>
<dl class="simple">
<dt>参数：</dt><dd><p><strong>x</strong> (oneflow.tensor) - 输入张量</p>
</dd>
<dt>返回类型：</dt><dd><p>oneflow.tensor</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gelu</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">gelu</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([-0.1543,  0.0000,  0.3457], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.glu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">glu</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.glu" title="Permalink to this definition">¶</a></dt>
<dd><p>glu 的公式为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[GLU(input) = GLU(a, b) = a \otimes sigmoid(b)\]</div></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>其中输入沿维度 dim 被切分成 a 和 b 两半，⊗ 是矩阵间的按元素积。</p>
</div>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">glu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([[0.9526, 1.9640],</span>
<span class="go">        [4.9954, 5.9980]], dtype=oneflow.float32)</span>
</pre></div>
</div>
<p>参考 <a class="reference internal" href="nn.html#oneflow.nn.GLU" title="oneflow.nn.GLU"><code class="xref py py-class docutils literal notranslate"><span class="pre">GLU</span></code></a> 获得更多细节。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.softsign">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">softsign</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.softsign" title="Permalink to this definition">¶</a></dt>
<dd><p>softsign 的公式为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[softsign(x) = \frac{x}{1 + |x|}\]</div></div>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softsign</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([0.5000, 0.6667, 0.7500], dtype=oneflow.float32)</span>
</pre></div>
</div>
<p>参考 <a class="reference internal" href="nn.html#oneflow.nn.Softsign" title="oneflow.nn.Softsign"><code class="xref py py-class docutils literal notranslate"><span class="pre">Softsign</span></code></a> 获得更多细节。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.softmax">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">softmax</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>将 Softmax 函数应用于 n 维 <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor 。并且重新缩放，
使输出 tensor 的元素于 [0,1] 范围内并且总和为 1 。</p>
<p>Softmax 的公式为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}\]</div></div>
<p>当输入张量是稀疏张量时，未指定的值将被视为 <code class="docutils literal notranslate"><span class="pre">-inf</span></code> 。</p>
<dl class="simple">
<dt>形状:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((*)\)</span> ，其中 <cite>*</cite> 表示任意数量的附加维度</p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((*)\)</span> ，与 <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> 相同的形状</p></li>
</ul>
</dd>
<dt>返回类型：</dt><dd><p>与 <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> 具有相同维度和形状的张量，其值在 [0, 1] 范围内</p>
</dd>
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>dim</strong> (int): 要计算 Softmax 的维度（沿 <cite>dim</cite> 的每个切片的总和为 1）</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.46716809</span><span class="p">,</span>  <span class="mf">0.40112534</span><span class="p">,</span>  <span class="mf">0.61984003</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.31244969</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.42528763</span><span class="p">,</span>  <span class="mf">1.47953856</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[[0.1575, 0.3754, 0.4671],</span>
<span class="go">         [0.0507, 0.1230, 0.8263]]], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.softplus">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">softplus</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.softplus" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素地应用此公式：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\text{Softplus}(x) = \frac{1}{\beta} * \log(1 + \exp(\beta * x))\]</div></div>
<p>更多细节参考 <a class="reference internal" href="nn.html#oneflow.nn.Softplus" title="oneflow.nn.Softplus"><code class="xref py py-class docutils literal notranslate"><span class="pre">Softplus</span></code></a> 。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.tanh">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">tanh</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.tanh" title="Permalink to this definition">¶</a></dt>
<dd><p>公式为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[out = \frac{e^x-e^{-x}}{e^x+e^{-x}}\]</div></div>
<p>更多信息请参考 <a class="reference internal" href="nn.html#oneflow.nn.Tanh" title="oneflow.nn.Tanh"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tanh</span></code></a> 。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.threshold">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">threshold</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.threshold" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.softshrink">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">softshrink</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.softshrink" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.silu">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">silu</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.silu" title="Permalink to this definition">¶</a></dt>
<dd><p>公式为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\text{silu}(x) = x * sigmoid(x)\]</div></div>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">silu</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([0.7311, 1.7616, 2.8577], dtype=oneflow.float32)</span>
</pre></div>
</div>
<p>更多信息请参考 <a class="reference internal" href="nn.html#oneflow.nn.SiLU" title="oneflow.nn.SiLU"><code class="xref py py-class docutils literal notranslate"><span class="pre">SiLU</span></code></a> 。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.mish">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">mish</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.mish" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素地应用此公式：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\text{mish}(x) = x * \text{tanh}(\text{softplus}(x))\]</div></div>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">mish</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([0.8651, 1.9440, 2.9865], dtype=oneflow.float32)</span>
</pre></div>
</div>
<p>更多细节参考 <a class="reference internal" href="nn.html#oneflow.nn.Mish" title="oneflow.nn.Mish"><code class="xref py py-class docutils literal notranslate"><span class="pre">Mish</span></code></a> 。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.one_hot">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">one_hot</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">off_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.one_hot" title="Permalink to this definition">¶</a></dt>
<dd><p>该算子根据输入张量生成一个 onehot 张量。</p>
<p>如果输入张量的秩为 <cite>N</cite>，相应的 onehot 张量的秩为 <cite>N+1</cite>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - 输入张量。</p></li>
<li><p><strong>num_classes</strong> (int) - 输出的 onehot 张量的长度。</p></li>
<li><p><strong>on_value</strong> (Union[int, float], optional) - 当 <cite>x[i] == i</cite> 时的填充值，默认为 1。</p></li>
<li><p><strong>off_value</strong> (Union[int, float], optional) - 当 <cite>x[i] != i</cite> 时的填充值，默认为 0。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>输入张量的数据类型应为：<cite>int32</cite> 或 <cite>int64</cite>。</p>
</div>
<dl class="simple">
<dt>返回值：</dt><dd><p>oneflow.Tensor</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">tensor([[1, 0, 0, 0, 0],</span>
<span class="go">        [0, 0, 0, 1, 0],</span>
<span class="go">        [0, 1, 0, 0, 0],</span>
<span class="go">        [0, 0, 1, 0, 0]], dtype=oneflow.int64)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.triplet_margin_loss">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">triplet_margin_loss</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.triplet_margin_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>文档参考自：<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.triplet_margin_loss.html?highlight=triplet_margin_loss">https://pytorch.org/docs/stable/generated/torch.nn.functional.triplet_margin_loss.html?highlight=triplet_margin_loss</a></p>
<p>在给定输入张量 <span class="math notranslate nohighlight">\(x1\)</span>, <span class="math notranslate nohighlight">\(x2\)</span>, <span class="math notranslate nohighlight">\(x3\)</span> 和值大于 <span class="math notranslate nohighlight">\(0\)</span> 的边距的情况下，创建一个测量三元组损失的标准。这用于测量样本之间的相对相似性。三元组由 <cite>a</cite>, <cite>p</cite> 和 <cite>n</cite> 组成（即分别为 <cite>锚点</cite>、<cite>正例</cite> 和 <cite>负例</cite> ）。所有输入张量的形状应为 <span class="math notranslate nohighlight">\((N, D)\)</span> 。</p>
<p>Vassileios Balntas、Edgar Riba 等人的 <a class="reference external" href="http://www.bmva.org/bmvc/2016/papers/paper119/index.html">Learning shallow convolutional feature descriptors with triplet losses</a> 一文中详细描述了距离交换。</p>
<p>小批量中每个样本的损失函数为：</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[L(a, p, n) = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\}\]</div></div>
<p>其中</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[d(x_i, y_i) = \left\lVert {\bf x}_i - {\bf y}_i \right\rVert_p\]</div></div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>margin</strong> (float, optional) - 默认为 <span class="math notranslate nohighlight">\(1\)</span></p></li>
<li><p><strong>p</strong> (float, optional) - 成对距离的范数，默认为 <span class="math notranslate nohighlight">\(2.0\)</span></p></li>
<li><p><strong>swap</strong> (bool, optional) - 默认为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 。V. Balntas、E. Riba 等人的 <a class="reference external" href="http://www.bmva.org/bmvc/2016/papers/paper119/index.html">Learning shallow convolutional feature descriptors with triplet losses</a> 一文中详细描述了距离交换。</p></li>
<li><p><strong>reduction</strong> (string, optional) - 指定应用于输出的 reduction：<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>。若值为 <code class="docutils literal notranslate"><span class="pre">'none'</span></code> ：不进行 reduction；值为 <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> ：输出的和将会除以输出中的元素数量；值为 <code class="docutils literal notranslate"><span class="pre">'sum'</span></code> ：输出将被求和。请注意：<code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code> 和 <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> 正逐渐被弃用，指定这二者的任何一个都将覆盖 <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>。默认值为 <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>。</p></li>
</ul>
</dd>
<dt>形状：</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((N, D)\)</span> ，其中 <span class="math notranslate nohighlight">\(D\)</span> 是向量维度。</p></li>
<li><p>Output: 若 <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> == <code class="docutils literal notranslate"><span class="pre">'none'</span></code> 则输出为形状为 <span class="math notranslate nohighlight">\((N)\)</span> 的张量，否则是一个标量。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">triplet_loss</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">TripletMarginLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anchor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">positive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">negative</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">triplet_loss</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">anchor</span><span class="p">),</span> <span class="n">flow</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">positive</span><span class="p">),</span> <span class="n">flow</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">negative</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span>
<span class="go">tensor(6.2971, dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.dropout">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">dropout</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Generator</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">addend</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tensor</span><a class="headerlink" href="#oneflow.nn.functional.dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>文档引用自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.dropout.html">https://pytorch.org/docs/stable/generated/torch.nn.functional.dropout.html</a> 。</p>
<p>在训练期间，使用来自伯努利分布的样本以概率 <code class="xref py py-attr docutils literal notranslate"><span class="pre">p</span></code> 将输入张量的一些元素随机归零。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) - 将应用 dropout 的张量。</p></li>
<li><p><strong>p</strong> (float) - 任一元素被归零的概率，默认为 0.5。</p></li>
<li><p><strong>training</strong> (bool) - 若为 True 则应用 dropout，默认为 True。</p></li>
<li><p><strong>generator</strong> (Generator, optional) - 用于采样的伪随机数发生器。</p></li>
<li><p><strong>addend</strong> (Tensor, optional) - 加入到 dropout 结果中的张量，它可以用于模型的残差连接结构。默认为 None。</p></li>
</ul>
</dd>
<dt>形状：</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((*)\)</span> ，输入可以为任何形状。</p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((*)\)</span> ，与输入形状相同。</p></li>
</ul>
</dd>
</dl>
<p>示例 1：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>


<span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
<span class="gp">... </span>   <span class="p">[</span>
<span class="gp">... </span>       <span class="p">[</span><span class="o">-</span><span class="mf">0.7797</span><span class="p">,</span> <span class="mf">0.2264</span><span class="p">,</span> <span class="mf">0.2458</span><span class="p">,</span> <span class="mf">0.4163</span><span class="p">],</span>
<span class="gp">... </span>       <span class="p">[</span><span class="mf">0.4299</span><span class="p">,</span> <span class="mf">0.3626</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4892</span><span class="p">,</span> <span class="mf">0.4141</span><span class="p">],</span>
<span class="gp">... </span>       <span class="p">[</span><span class="o">-</span><span class="mf">1.4115</span><span class="p">,</span> <span class="mf">1.2183</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5503</span><span class="p">,</span> <span class="mf">0.6520</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
<span class="gp">... </span>   <span class="p">[</span>
<span class="gp">... </span>       <span class="p">[</span><span class="o">-</span><span class="mf">0.7797</span><span class="p">,</span> <span class="mf">0.2264</span><span class="p">,</span> <span class="mf">0.2458</span><span class="p">,</span> <span class="mf">0.4163</span><span class="p">],</span>
<span class="gp">... </span>       <span class="p">[</span><span class="mf">0.4299</span><span class="p">,</span> <span class="mf">0.3626</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4892</span><span class="p">,</span> <span class="mf">0.4141</span><span class="p">],</span>
<span class="gp">... </span>       <span class="p">[</span><span class="o">-</span><span class="mf">1.4115</span><span class="p">,</span> <span class="mf">1.2183</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5503</span><span class="p">,</span> <span class="mf">0.6520</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">generator</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
</pre></div>
</div>
<p>示例 2：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>


<span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
<span class="gp">... </span>   <span class="p">[</span>
<span class="gp">... </span>       <span class="p">[</span><span class="o">-</span><span class="mf">0.7797</span><span class="p">,</span> <span class="mf">0.2264</span><span class="p">,</span> <span class="mf">0.2458</span><span class="p">,</span> <span class="mf">0.4163</span><span class="p">],</span>
<span class="gp">... </span>       <span class="p">[</span><span class="mf">0.4299</span><span class="p">,</span> <span class="mf">0.3626</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4892</span><span class="p">,</span> <span class="mf">0.4141</span><span class="p">],</span>
<span class="gp">... </span>       <span class="p">[</span><span class="o">-</span><span class="mf">1.4115</span><span class="p">,</span> <span class="mf">1.2183</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5503</span><span class="p">,</span> <span class="mf">0.6520</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">addend</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">addend</span><span class="o">=</span><span class="n">addend</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> 
<span class="go">tensor([[ 0.2203,  1.2264,  1.2458,  1.4163],</span>
<span class="go">        [ 1.4299,  1.3626,  0.5108,  1.4141],</span>
<span class="go">        [-0.4115,  2.2183,  0.4497,  1.6520]], dtype=oneflow.float32)</span>
</pre></div>
</div>
<p>参考 <a class="reference internal" href="nn.html#oneflow.nn.Dropout" title="oneflow.nn.Dropout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code></a> 获得更多细节。</p>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.affine_grid">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">affine_grid</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.affine_grid" title="Permalink to this definition">¶</a></dt>
<dd><p>此接口与 PyTorch 一致。文档参考自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.affine_grid.html?highlight=affine_grid#torch.nn.functional.affine_grid">https://pytorch.org/docs/stable/generated/torch.nn.functional.affine_grid.html?highlight=affine_grid#torch.nn.functional.affine_grid</a> 。</p>
<p>给定一批仿射矩阵 <code class="xref py py-attr docutils literal notranslate"><span class="pre">theta</span></code> ，生成 2D 或 3D 流场（采样网格）。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>此函数通常与 <a class="reference internal" href="#oneflow.nn.functional.grid_sample" title="oneflow.nn.functional.grid_sample"><code class="xref py py-func docutils literal notranslate"><span class="pre">grid_sample()</span></code></a> 结合使用来构建 <a class="reference external" href="https://arxiv.org/abs/1506.02025">Spatial Transformer Networks</a> 。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>theta</strong> (Tensor) - 形状为 (<span class="math notranslate nohighlight">\(N, 2, 3\)</span>)（2D 场景）或形状为 (<span class="math notranslate nohighlight">\(N, 3, 4\)</span>)（3D 场景）的仿射矩阵的输入批量。</p></li>
<li><p><strong>size</strong> (oneflow.Size) - 目标输出图像大小。形状为 (<span class="math notranslate nohighlight">\(N, C, H, W\)</span>)（2D 场景）或 (<span class="math notranslate nohighlight">\(N, C, D, H, W\)</span>)（3D 场景），例如 <code class="docutils literal notranslate"><span class="pre">oneflow.Size((32,</span> <span class="pre">3,</span> <span class="pre">24,</span> <span class="pre">24))</span></code>。</p></li>
<li><p><strong>align_corners</strong> (bool) - 如果为 <code class="docutils literal notranslate"><span class="pre">True</span></code>，则考虑 <code class="docutils literal notranslate"><span class="pre">-1</span></code> 和 <code class="docutils literal notranslate"><span class="pre">1</span></code> 来指代角像素的中心，而不是图像的角。参考 <a class="reference internal" href="#oneflow.nn.functional.grid_sample" title="oneflow.nn.functional.grid_sample"><code class="xref py py-func docutils literal notranslate"><span class="pre">grid_sample()</span></code></a> 来获得更详细的描述。由 <a class="reference internal" href="#oneflow.nn.functional.affine_grid" title="oneflow.nn.functional.affine_grid"><code class="xref py py-func docutils literal notranslate"><span class="pre">affine_grid()</span></code></a> 生成的网格应使用与此选项相同的设置传递给 <a class="reference internal" href="#oneflow.nn.functional.grid_sample" title="oneflow.nn.functional.grid_sample"><code class="xref py py-func docutils literal notranslate"><span class="pre">grid_sample()</span></code></a>。默认为 <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p></li>
</ul>
</dd>
<dt>返回值：</dt><dd><p>output (Tensor) - 形状为 (<span class="math notranslate nohighlight">\(N, H, W, 2\)</span>) 的输出张量。</p>
</dd>
</dl>
<p>示例：</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">affine_grid</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">flow</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span>
<span class="go">tensor([[[[ 0., -3.],</span>
<span class="go">          [ 2.,  5.]],</span>

<span class="go">         [[ 4.,  7.],</span>
<span class="go">          [ 6., 15.]]]], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.grid_sample">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">grid_sample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'bilinear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.grid_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>此接口与 PyTorch 一致。文档参考自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.grid_sample.html?highlight=grid_sample#torch.nn.functional.grid_sample">https://pytorch.org/docs/stable/generated/torch.nn.functional.grid_sample.html?highlight=grid_sample#torch.nn.functional.grid_sample</a></p>
<p>给定 <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> 和流场 <code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code>，使用 <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> 和 <code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code> 中的像素位置计算输出。目前，仅支持空间 (4-D) 和体积 (5-D) 输入。在空间 (4-D) 情况下，对于形状为 <span class="math notranslate nohighlight">\((N, C, H_{in}, W_{in})\)</span> 的输入和形状为 <span class="math notranslate nohighlight">\((N, H_{out}, W_{out}, 2)\)</span> 的网格，输出将具有形状 <span class="math notranslate nohighlight">\((N, C, H_{out}, W_{out})\)</span>。</p>
<p>对于每个输出位置 <code class="docutils literal notranslate"><span class="pre">output[n,</span> <span class="pre">:,</span> <span class="pre">h,</span> <span class="pre">w]</span></code>，大小为 2 的向量 <code class="docutils literal notranslate"><span class="pre">grid[n,</span> <span class="pre">h,</span> <span class="pre">w]</span></code> 指定输入像素位置 <code class="docutils literal notranslate"><span class="pre">x</span></code> 和 <code class="docutils literal notranslate"><span class="pre">y</span></code>，用于插值输出值 <code class="docutils literal notranslate"><span class="pre">output[n,</span> <span class="pre">:,</span> <span class="pre">h,</span> <span class="pre">w]</span></code>。在 5D 输入的情况下，<code class="docutils literal notranslate"><span class="pre">grid[n,</span> <span class="pre">d,</span> <span class="pre">h,</span> <span class="pre">w]</span></code> 指定用于插值 <code class="docutils literal notranslate"><span class="pre">output[n,</span> <span class="pre">:,</span> <span class="pre">d,</span> <span class="pre">h,</span> <span class="pre">w]</span></code> 的 <code class="docutils literal notranslate"><span class="pre">x</span></code>、<code class="docutils literal notranslate"><span class="pre">y</span></code>、<code class="docutils literal notranslate"><span class="pre">z</span></code> 像素位置。<code class="xref py py-attr docutils literal notranslate"><span class="pre">mode</span></code> 参数指定对输入像素进行采样的最近或双线性插值方法。网格指定由输入空间维度归一化的采样像素位置。因此，它应该具有 <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code> 范围内的大多数值。例如，<code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">-1,</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">-1</span></code> 是输入的左上角像素，<code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">1,</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">1</span></code> 是输入的右下角像素。</p>
<dl class="simple">
<dt>如果 <code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code> 的值在 <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code> 之外，相应的输出按照 <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding_mode</span></code> 的定义进行处理。那么：</dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">padding_mode="zeros"</span></code>: 使用 <code class="docutils literal notranslate"><span class="pre">0</span></code> 表示越界网格位置。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding_mode="border"</span></code>: 使用边界值表示越界网格位置。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding_mode="reflection"</span></code>: 使用边界反映的位置处的值表示越界网格位置。对于远离边界的位置，它将一直被反射直到进入边界。例如（归一化）像素位置 <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">-3.5</span></code> 由边界 <code class="docutils literal notranslate"><span class="pre">-1</span></code> 反射并变为 <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">1.5</span></code>，然后由边界 <code class="docutils literal notranslate"><span class="pre">1</span></code> 反射并变为 <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">-0.5</span></code>。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>此函数通常与 <a class="reference internal" href="#oneflow.nn.functional.grid_sample" title="oneflow.nn.functional.grid_sample"><code class="xref py py-func docutils literal notranslate"><span class="pre">grid_sample()</span></code></a> 结合使用来构建 <a class="reference external" href="https://arxiv.org/abs/1506.02025">Spatial Transformer Networks</a> 。</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code> 中的 NaN 值将被解释为 <code class="docutils literal notranslate"><span class="pre">-1</span></code>。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - 形状为 <span class="math notranslate nohighlight">\((N, C, H_{in}, W_{in})\)</span> （4D 情况下）或形状为 <span class="math notranslate nohighlight">\((N, C, D_{in}, H_{in}, W_{in})\)</span> （5D 情况下）的输入张量</p></li>
<li><p><strong>grid</strong> (Tensor) - 形状为 <span class="math notranslate nohighlight">\((N, H_{out}, W_{out}, 2)\)</span> （4D 情况下）或形状为 <span class="math notranslate nohighlight">\((N, D_{out}, H_{out}, W_{out}, 3)\)</span> （5D 情况下）的流场</p></li>
<li><p><strong>mode</strong> (str) - 计算输出值的插值模式：<code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code> | <code class="docutils literal notranslate"><span class="pre">'nearest'</span></code> | <code class="docutils literal notranslate"><span class="pre">'bicubic'</span></code>。默认为 <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code>。注意 <code class="docutils literal notranslate"><span class="pre">mode='bicubic'</span></code> 仅支持 4D 输入。当 <code class="docutils literal notranslate"><span class="pre">mode='bilinear'</span></code> 且输入是 5D 时，内部使用的插值模式实际上是三线性的。然而，当输入是 4D 时，插值模式将是双线性的。</p></li>
<li><p><strong>padding_mode</strong> (str) - 外部网格值的填充模式：<code class="docutils literal notranslate"><span class="pre">'zeros'</span></code> | <code class="docutils literal notranslate"><span class="pre">'border'</span></code> | <code class="docutils literal notranslate"><span class="pre">'reflection'</span></code>。默认为 <code class="docutils literal notranslate"><span class="pre">'zeros'</span></code>。</p></li>
<li><p><strong>align_corners</strong> (bool) - 在几何上，我们将输入的像素视为正方形而不是点。如果设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code>，则极值 （<code class="docutils literal notranslate"><span class="pre">-1</span></code>  和 <code class="docutils literal notranslate"><span class="pre">1</span></code>）被认为指代输入角像素的中心点。如果设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code>，则它们被认为是指输入角像素的角点，从而使采样与分辨率无关。 此选项与 <a class="reference internal" href="#oneflow.nn.functional.interpolate" title="oneflow.nn.functional.interpolate"><code class="xref py py-func docutils literal notranslate"><span class="pre">interpolate()</span></code></a> 中的 <code class="docutils literal notranslate"><span class="pre">align_corners</span></code> 选项一致，因此此处使用的任何选项也应用于在网格采样之前调整输入图像的大小。默认为 <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p></li>
</ul>
</dd>
<dt>返回值：</dt><dd><p>output (Tensor) - 输出张量。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">mode='bicubic'</span></code> 使用 <span class="math notranslate nohighlight">\(\alpha=-0.75\)</span> 的 <a class="reference external" href="https://en.wikipedia.org/wiki/Bicubic_interpolation">三次卷积算法</a> 实现。常数 <span class="math notranslate nohighlight">\(\alpha\)</span> 可能因包而异。例如 <a class="reference external" href="https://github.com/python-pillow/Pillow/blob/4634eafe3c695a014267eefdce830b4a825beed7/src/libImaging/Resample.c#L51">PIL</a> 和 <a class="reference external" href="https://github.com/opencv/opencv/blob/f345ed564a06178670750bad59526cfa4033be55/modules/imgproc/src/resize.cpp#L908">OpenCV</a> 分别使用 -0.5 和 -0.75。该算法可能会“超出”它的插值范围。例如，输入位于 <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">255]</span></code> 中的插值时，它可能会产生负值或大于 <cite>255</cite> 的值。使用 <code class="xref py py-func docutils literal notranslate"><span class="pre">flow.clamp()</span></code> 钳制结果以确保它们在有效范围内。</p>
</div>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[[[</span><span class="o">-</span><span class="mf">0.9</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2000</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.333</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>
<span class="gp">... </span>     <span class="p">[[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.3333</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.200</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]]</span>
<span class="gp">... </span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grid</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np_grid</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">grid_sample</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'nearest'</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">'zeros'</span><span class="p">,</span>
<span class="gp">... </span>                                       <span class="n">align_corners</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span>
<span class="go">tensor([[[[0., 8., 5., 7., 9.],</span>
<span class="go">          [1., 8., 5., 8., 0.]]]], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.interpolate">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">interpolate</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recompute_scale_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.interpolate" title="Permalink to this definition">¶</a></dt>
<dd><p>此接口与 PyTorch 一致。文档参考自：<a class="reference external" href="https://pytorch.org/docs/1.9.0/_modules/torch/nn/functional.html#interpolate">https://pytorch.org/docs/1.9.0/_modules/torch/nn/functional.html#interpolate</a> 。</p>
<p>上/下采样输入到给定大小或给定 <code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_factor</span></code>。用于插值的算法由 <code class="xref py py-attr docutils literal notranslate"><span class="pre">mode</span></code> 确定。
目前支持时间、空间和体积采样，即预期输入为三维、四维或五维形状。</p>
<p>输入大小解释为：<code class="docutils literal notranslate"><span class="pre">mini-batch</span> <span class="pre">x</span> <span class="pre">channels</span> <span class="pre">x</span> <span class="pre">[optional</span> <span class="pre">depth]</span> <span class="pre">x</span> <span class="pre">[optional</span> <span class="pre">height]</span> <span class="pre">x</span> <span class="pre">width</span></code>。</p>
<p>可用于调整大小的模式有：<cite>nearest</cite>、<cite>linear</cite> （仅限 3D）、<cite>bilinear</cite>、<cite>bicubic</cite> （仅限 4D）、<cite>trilinear</cite> （仅限 5D）、<cite>area</cite>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - 输入张量。</p></li>
<li><p><strong>size</strong> - 输出空间大小，可以为一个、两个或三个 int 组成的 <code class="docutils literal notranslate"><span class="pre">tuple</span></code>。</p></li>
<li><p><strong>scale_factor</strong> (float or Tuple[float]) - 空间大小的乘数。如果是元组，则必须匹配输入大小。</p></li>
<li><p><strong>mode</strong> (str) - 选择用于上采样的算法：<code class="docutils literal notranslate"><span class="pre">'nearest'</span></code> | <code class="docutils literal notranslate"><span class="pre">'linear'</span></code> | <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code> | <code class="docutils literal notranslate"><span class="pre">'bicubic'</span></code> | <code class="docutils literal notranslate"><span class="pre">'trilinear'</span></code> | <code class="docutils literal notranslate"><span class="pre">'area'</span></code>。默认为 <code class="docutils literal notranslate"><span class="pre">'nearest'</span></code></p></li>
<li><p><strong>align_corners</strong> (bool, optional) - 几何上，我们将输入和输出的像素视为正方形而不是点。如果设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code>，则输入和输出张量由其角像素的中心点对齐，保留角像素处的值。如果设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code>，则输入和输出张量通过其角像素的角点对齐，并且插值对边界外的值使用边缘值填充，当 <code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_factor</span></code> 保持相同时，此操作与输入大小无关。这仅在模式为 <cite>linear</cite>、<cite>bilinear</cite>、<cite>bicubic</cite> 或 <cite>trilinear</cite> 时有效。默认值：<code class="docutils literal notranslate"><span class="pre">False</span></code>。</p></li>
<li><p><strong>recompute_scale_factor</strong> (bool, optional) - 重新计算 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 以用于插值计算。当 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 作为参数传递时，它用于计算 <code class="docutils literal notranslate"><span class="pre">output_size</span></code>。如果 <code class="docutils literal notranslate"><span class="pre">recompute_scale_factor</span></code> 为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 或未指定，传入的 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 将用于插值计算。否则，将根据用于插值计算的输出和输入大小计算新的 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> （即计算将与显式传入计算的 <code class="docutils literal notranslate"><span class="pre">output_size</span></code> 相同）。请注意，当 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 为浮点数时，由于舍入和精度问题，重新计算的 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 可能与传入的值不同。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>使用 <code class="docutils literal notranslate"><span class="pre">mode='bicubic'</span></code>，可能会导致过冲，也就是它可以为图像产生负值或大于 255 的值。如果要减少显示图像时的过冲，请显式调用 <code class="docutils literal notranslate"><span class="pre">result.clamp(min=0,</span> <span class="pre">max=255)</span></code></p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>若 <code class="docutils literal notranslate"><span class="pre">align_corners</span> <span class="pre">=</span> <span class="pre">True</span></code>，线性插值模式（线性、双线性和三线性）不会按比例对齐输出和输入像素，因此输出值可能取决于输入大小。这是 0.3.1 之前这些模式的默认行为，此后的默认行为是 <code class="docutils literal notranslate"><span class="pre">align_corners</span> <span class="pre">=</span> <span class="pre">False</span></code>。有关这如何影响输出的具体示例，请参见 <code class="xref py py-class docutils literal notranslate"><span class="pre">Upsample</span></code></p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>当指定 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 时，如果 <code class="docutils literal notranslate"><span class="pre">recompute_scale_factor=True</span></code>，则 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 用于计算输出大小，然后用于推断插值的新比例。</p>
</div>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="o">&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="n">output</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">1.0000</span><span class="p">,</span> <span class="mf">1.2500</span><span class="p">,</span> <span class="mf">1.7500</span><span class="p">,</span> <span class="mf">2.2500</span><span class="p">,</span> <span class="mf">2.7500</span><span class="p">,</span> <span class="mf">3.2500</span><span class="p">,</span> <span class="mf">3.7500</span><span class="p">,</span> <span class="mf">4.0000</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">oneflow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.ctc_greedy_decoder">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">ctc_greedy_decoder</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.ctc_greedy_decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>对输入中给出的 logits 执行贪婪解码（最佳路径）。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>log_probs</strong> (oneflow.Tensor) - 形状为 <code class="docutils literal notranslate"><span class="pre">[input_length,</span> <span class="pre">batch_size,</span> <span class="pre">num_labels]</span></code> 的张量。输出的对数概率（例如，使用 <code class="docutils literal notranslate"><span class="pre">flow.nn.logsoftmax()</span></code> 获得）。</p></li>
<li><p><strong>input_lengths</strong> (oneflow.Tensor) - 形状为 <code class="docutils literal notranslate"><span class="pre">[batch_size]</span></code> 的张量。它表示输入的长度。并且在序列被填充到相等长度的假设下，为每个序列指定长度以实现掩码。</p></li>
<li><p><strong>merge_repeated</strong> (bool, optional) - 如果 <code class="docutils literal notranslate"><span class="pre">merge_repeated</span></code> 为 <code class="docutils literal notranslate"><span class="pre">True</span></code>，则合并输出中的重复类。这意味着如果连续 logits 的最大索引相同，则仅发出其中的第一个。默认为 <code class="docutils literal notranslate"><span class="pre">True</span></code>。</p></li>
</ul>
</dd>
<dt>返回值：</dt><dd><ul class="simple">
<li><p>decoded(oneflow.Tensor) - 形状为 [batch_size, input_length] 的张量，解码后的输出。</p></li>
<li><p>neg_sum_logits(oneflow.Tensor) - 一个浮点矩阵 (batch_size x 1)，对于找到的序列，包含每个时间帧最大 logit 总和的负数。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_probs</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span>
<span class="gp">... </span>        <span class="p">[[</span><span class="o">-</span><span class="mf">1.54</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.20</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.95</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.65</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.81</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.84</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.74</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.58</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.55</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.12</span><span class="p">]],</span>
<span class="gp">... </span>        <span class="p">[[</span><span class="o">-</span><span class="mf">1.68</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.48</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.89</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.30</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.07</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.13</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.45</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.24</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.61</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.66</span><span class="p">]],</span>
<span class="gp">... </span>        <span class="p">[[</span><span class="o">-</span><span class="mf">1.56</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.40</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.83</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.67</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.48</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.20</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.95</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.24</span><span class="p">]],</span>
<span class="gp">... </span>        <span class="p">[[</span><span class="o">-</span><span class="mf">2.09</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.76</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.36</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.67</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.45</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.85</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.48</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.34</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.16</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.55</span><span class="p">]],</span>
<span class="gp">... </span>    <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_lengths</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">decoded</span><span class="p">,</span> <span class="n">neg_sum_logits</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">ctc_greedy_decoder</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">decoded</span>
<span class="go">tensor([[1, 3, 1, 2],</span>
<span class="go">        [0, 2, 0, 0]], dtype=oneflow.int64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neg_sum_logits</span>
<span class="go">tensor([[5.2600],</span>
<span class="go">        [4.7900]], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.sparse_softmax_cross_entropy">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">sparse_softmax_cross_entropy</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.sparse_softmax_cross_entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>此接口与 TensorFlow 一致。文档参考自：<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits">https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits</a></p>
<p>计算 <cite>logits</cite> 和标签之间的稀疏 softmax 交叉熵。</p>
<p>测量类别互斥（每个条目恰好属于一个类别）的离散分类任务中的概率误差。例如，每张 CIFAR-10 图像都标有一个且只有一个标签：图像可以是狗或卡车，但不能同时是两者。一个常见的用例是具有形状 <cite>[batch_size, num_classes]</cite> 的 <cite>logits</cite> 和具有形状 <cite>[batch_size]</cite> 的标签，但支持更高的维度，在这种情况下，假设第 <cite>dim</cite> 维度的大小为 <cite>num_classes</cite>。<cite>logits</cite> 的数据类型必须为 <cite>float16</cite>、<cite>float32</cite> 或 <cite>float64</cite>，标签的数据类型必须为 <cite>int32</cite> 或 <cite>int64</cite>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>labels</strong> (Tensor) - 具有 <code class="docutils literal notranslate"><span class="pre">[d_0,</span> <span class="pre">d_1,</span> <span class="pre">...,</span> <span class="pre">d_{r-1}]</span></code> 的形状（其中 <cite>r</cite> 是标签和输出的 rank），其数据类型是 <cite>int32</cite> 或 <cite>int64</cite>。标签中的每个条目必须是 <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">num_classes)</span></code> 中的索引。</p></li>
<li><p><strong>logits</strong> (Tensor) - 具有 <code class="docutils literal notranslate"><span class="pre">[d_0,</span> <span class="pre">d_1,</span> <span class="pre">...,</span> <span class="pre">d_{r-1},</span> <span class="pre">num_classes]</span></code> 的形状且数据类型是 <cite>float16</cite>、<cite>float32</cite> 或 <cite>float64</cite> 的每个标签激活（通常是线性输出）。这些激活能被解释为非标准化的对数概率。</p></li>
</ul>
</dd>
<dt>返回值：</dt><dd><p>output (Tensor) - 与标签具有相同形状且与 <cite>logits</cite> 相同类型的张量，具有 softmax 交叉熵损失。</p>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
<span class="gp">... </span>     <span class="p">[</span>
<span class="gp">... </span>         <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">],</span>
<span class="gp">... </span>         <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">],</span>
<span class="gp">... </span>         <span class="p">[</span><span class="o">-</span><span class="mf">100.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">100.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">100.0</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">]</span>
<span class="gp">... </span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np_logits</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np_labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span>
<span class="go">tensor([ 2.9751e-01,  1.1448e+00, -1.4305e-06], dtype=oneflow.float32)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.embedding">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">embedding</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad_by_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.embedding" title="Permalink to this definition">¶</a></dt>
<dd><p>一个简单的查找表，可以在固定的字典和大小中查找嵌入项。
该模块通常用于使用索引检索词嵌入。模块的输入是索引列表和嵌入矩阵，输出是相应的词嵌入。查看 <a class="reference internal" href="nn.html#oneflow.nn.Embedding" title="oneflow.nn.Embedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">oneflow.nn.Embedding</span></code></a> 获得更多细节。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> (LongTensor) - 包含嵌入矩阵中的索引的张量。</p></li>
<li><p><strong>weight</strong> (Tensor) - 行数等于最大可能索引 <code class="docutils literal notranslate"><span class="pre">+1</span></code> 且列数等于嵌入大小的嵌入矩阵。</p></li>
<li><p><strong>padding_idx</strong> (int, optional) - 如果指定，则 <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding_idx</span></code> 处的条目不会影响梯度；因此 <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding_idx</span></code> 处的嵌入向量在训练期间不会更新，即它仍然是一个固定的 <code class="docutils literal notranslate"><span class="pre">pad</span></code>。</p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># a batch of 2 samples of 4 indices each</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># an embedding matrix containing 10 tensors of size 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">embedding_matrix</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">shape</span>
<span class="go">oneflow.Size([2, 4, 3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># example with padding_idx</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">embedding_matrix</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">shape</span>
<span class="go">oneflow.Size([1, 4, 3])</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.linear">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">linear</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.linear" title="Permalink to this definition">¶</a></dt>
<dd><p>对输入数据应用线性变换 <span class="math notranslate nohighlight">\(y = xA^T + b\)</span>。</p>
<dl class="simple">
<dt>形状：</dt><dd><ul class="simple">
<li><p>Input - <span class="math notranslate nohighlight">\((N, *, in\_features)\)</span>，其中 <cite>N</cite> 表示 batch size，<cite>*</cite> 表示任意数量的附加维度。</p></li>
<li><p>Weight - <span class="math notranslate nohighlight">\((out\_features, in\_features)\)</span></p></li>
<li><p>Bias - <span class="math notranslate nohighlight">\((out\_features)\)</span></p></li>
<li><p>Output - <span class="math notranslate nohighlight">\((N, *, out\_features)\)</span></p></li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weight</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">oneflow.Size([128, 30])</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="oneflow.nn.functional.cross_entropy">
<code class="sig-prename descclassname"><span class="pre">oneflow.nn.functional.</span></code><code class="sig-name descname"><span class="pre">cross_entropy</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.nn.functional.cross_entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>文档参考自： <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html?highlight=nn%20functional%20cross_entropy#torch.nn.functional.cross_entropy">https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html?highlight=nn%20functional%20cross_entropy#torch.nn.functional.cross_entropy</a> 。
查看 <a class="reference internal" href="nn.html#oneflow.nn.CrossEntropyLoss" title="oneflow.nn.CrossEntropyLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code></a> 获得更多细节。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) : 2D 损失的情况下为 <span class="math notranslate nohighlight">\((N, C)\)</span> ，其中 <cite>C = 类的数量</cite> 或 <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> ；K 维损失下为 <span class="math notranslate nohighlight">\((N, C, d_1, d_2, ..., d_K)\)</span> ，其中 <span class="math notranslate nohighlight">\(K \geq 1\)</span> 。 <cite>input</cite> 需包括未被规格化的指数。（通常被称为 logits）</p></li>
<li><p><strong>target</strong> (Tensor) : 如果包括了类索引，形状为 <span class="math notranslate nohighlight">\((N)\)</span> ，其中每个值为 <span class="math notranslate nohighlight">\(0 \leq \text{targets}[i] \leq C-1\)</span> ，在 K 维损失下，则为 <span class="math notranslate nohighlight">\((N, d_1, d_2, ..., d_K)\)</span> ，其中 <span class="math notranslate nohighlight">\(K \geq 1\)</span> 。如果包括类可能性，则与输入相同。</p></li>
<li><p><strong>weight</strong> (Tensor, 可选): 一个手动重设尺寸的权重，分配给每个类。如果被指定，需要是一个尺寸为 <cite>C</cite> 的张量。</p></li>
<li><p><strong>ignore_index</strong> (int, 可选): 指定一个将被忽略且不计入输入梯度的目标值。当 <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code> 为真时，损失将为不被忽略的目标的平均。注意 <code class="xref py py-attr docutils literal notranslate"><span class="pre">ignore_index</span></code> 只有在目标包括类索引时可用。默认值：-100</p></li>
<li><dl class="simple">
<dt><strong>reduction</strong> (string, 可选): 指定应用于输出的转置：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: 没有转置将被应用，
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: 输出的和将被除以输出元素个数， <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: 输出将被总和。注意： <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code> 和 <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> 即将被弃用，而与此同时
指定任意两参数都会覆盖 <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> 。默认值： <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<p>示例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow</span> <span class="kn">as</span> <span class="nn">flow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">oneflow.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>
</div>
</div>

      </article>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="autograd.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">oneflow.autograd</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="nn.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">oneflow.nn</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2020, OneFlow
            |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>.
            |
            <a class="muted-link" href="_sources/functional.rst.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">oneflow.nn.functional</a><ul>
<li><a class="reference internal" href="#functional-operations-for-neural-networks">Functional operations for neural networks</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </main>
</div>
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="_static/scripts/main.js?digest=e931d09b2a40c1bb82b542effe772014573baf67"></script></body>
</html>