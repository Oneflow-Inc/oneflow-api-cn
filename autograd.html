<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="oneflow.cuda" href="cuda.html" /><link rel="prev" title="oneflow.nn.functional" href="functional.html" />

    <meta name="generator" content="sphinx-3.5.4, furo 2021.04.11.beta34"/>
        <title>oneflow.autograd - OneFlow documentation</title>
      <link rel="stylesheet" href="_static/styles/furo.css?digest=59ab60ac09ea94ccfe6deddff6d715cce948a6fc">
    <link rel="stylesheet" href="_static/pygments.css">
    <link media="(prefers-color-scheme: dark)" rel="stylesheet" href="_static/pygments_dark.css">
    


<style>
  :root {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }

  /* For allowing end-user-specific overrides */
  .override-light {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  .override-dark {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
</style><link rel="stylesheet" href="_static/styles/furo-extensions.css?digest=d391b54134226e4196576da3bdb6dddb7e05ba2b"></head>
  <body dir="">
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke-width="1.5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z"/>
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">OneFlow  documentation</div></a>
    </div>
    <div class="header-right">
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">OneFlow  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html">
  <input class="sidebar-search" placeholder=Search name="q">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
</ul>
<p class="caption"><span class="caption-text">OneFlow Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="oneflow.html">oneflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">oneflow.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">oneflow.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="functional.html">oneflow.nn.functional</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">oneflow.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">oneflow.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">oneflow.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">oneflow.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">oneflow.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">oneflow.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="module.html">oneflow.nn.Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph.html">oneflow.nn.Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="image.html">oneflow.nn.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">oneflow.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="env.html">oneflow.env</a></li>
<li class="toctree-l1"><a class="reference internal" href="comm.html">oneflow.comm</a></li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <main class="main">
    <div class="content">
      <article role="main">
        <label class="toc-overlay-icon toc-content-icon" for="__toc">
          <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
        </label>
        <div class="section" id="oneflow-autograd">
<h1>oneflow.autograd<a class="headerlink" href="#oneflow-autograd" title="Permalink to this headline">¶</a></h1>
<div class="section" id="functions-and-classes-for-autograd">
<h2>Functions and classes for autograd.<a class="headerlink" href="#functions-and-classes-for-autograd" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="oneflow.autograd.Function">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">oneflow.autograd.</span></code><code class="sig-name descname"><span class="pre">Function</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.autograd.Function" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class to create custom autograd.Function.</p>
<p>To create a custom autograd.Function, subclass this class and implement the <code class="docutils literal notranslate"><span class="pre">forward()</span></code>
and <code class="docutils literal notranslate"><span class="pre">backward()</span></code> static methods. Then, to use your custom op in the forward pass, call the
class method <code class="docutils literal notranslate"><span class="pre">apply()</span></code> or <code class="docutils literal notranslate"><span class="pre">__call__()</span></code>. Do not call <code class="docutils literal notranslate"><span class="pre">forward()</span></code> directly.</p>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Exp</span><span class="p">(</span><span class="n">Function</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="n">result</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="k">return</span> <span class="n">grad_output</span> <span class="o">*</span> <span class="n">result</span>

<span class="c1"># Use it by calling the apply method or __call__ method</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Exp</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1"># output = Exp()(input)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="oneflow.autograd.Function.__call__">
<code class="sig-name descname"><span class="pre">__call__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.autograd.Function.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.apply()</span></code>.</p>
</dd></dl>
<dl class="py method">
<dt id="oneflow.autograd.Function.apply">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">apply</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#oneflow.autograd.Function.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate output tensors and build backward graph.</p>
</dd></dl>
</dd></dl>
<span class="target" id="module-oneflow.autograd"></span><p>Copyright 2020 The OneFlow Authors. All rights reserved.</p>
<p>Licensed under the Apache License, Version 2.0 (the “License”);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<blockquote>
<div><p><a class="reference external" href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></p>
</div></blockquote>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an “AS IS” BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
<dl class="py function">
<dt id="oneflow.autograd.backward">
<code class="sig-prename descclassname"><span class="pre">oneflow.autograd.</span></code><code class="sig-name descname"><span class="pre">backward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_tensors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">create_graph</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> → <span class="pre">None</span><a class="headerlink" href="#oneflow.autograd.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>The documentation is referenced from:
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.autograd.backward.html#torch.autograd.backward">https://pytorch.org/docs/stable/generated/torch.autograd.backward.html#torch.autograd.backward</a></p>
<p>Computes the sum of gradients of given tensors with respect to graph leaves.</p>
<p>The graph is differentiated using the chain rule. If any of <code class="docutils literal notranslate"><span class="pre">tensors</span></code> are non-scalar (i.e.
their data has more than one element) and require gradient, then the Jacobian-vector product
would be computed, in this case the function additionally requires specifying <code class="docutils literal notranslate"><span class="pre">grad_tensors</span></code>.
It should be a sequence of matching length, that contains the “vector” in the Jacobian-vector
product, usually the gradient of the differentiated function w.r.t. corresponding tensors.
(<code class="docutils literal notranslate"><span class="pre">None</span></code> is an acceptable value for all tensors that don’t need gradient.)</p>
<p>This function accumulates gradients in the leaves - you might need to zero <code class="docutils literal notranslate"><span class="pre">.grad</span></code> attributes
or set them to <code class="docutils literal notranslate"><span class="pre">None</span></code> before calling it.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using this method with <code class="docutils literal notranslate"><span class="pre">create_graph=True</span></code> will create a reference cycle between the
parameter and its gradient which can cause a memory leak. We recommend using
<code class="docutils literal notranslate"><span class="pre">autograd.grad</span></code> when creating the graph to avoid this. If you have to use this function,
make sure to reset the <code class="docutils literal notranslate"><span class="pre">.grad</span></code> fields of your parameters to <code class="docutils literal notranslate"><span class="pre">None</span></code> after use to break
the cycle and avoid the leak.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> (<a class="reference internal" href="tensor.html#oneflow.Tensor" title="oneflow.Tensor"><em>Tensor</em></a><em> or </em><em>Sequence</em><em>[</em><a class="reference internal" href="tensor.html#oneflow.Tensor" title="oneflow.Tensor"><em>Tensor</em></a><em>]</em>) – Tensors of which the derivative will be computed.</p></li>
<li><p><strong>grad_tensors</strong> (<a class="reference internal" href="tensor.html#oneflow.Tensor" title="oneflow.Tensor"><em>Tensor</em></a><em> or </em><em>Sequence</em><em>[</em><a class="reference internal" href="tensor.html#oneflow.Tensor" title="oneflow.Tensor"><em>Tensor</em></a><em>]</em><em>, </em><em>optional</em>) – The “vector” in the Jacobian-vector
product, usually gradients each element of corresponding tensors. (None values can be
specified for scalar Tensors or ones that don’t require grad.)</p></li>
<li><p><strong>retain_graph</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the graph used to compute the grads will be
reset after backward is complete. Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>. Note that in nearly all cases
setting this option to <code class="docutils literal notranslate"><span class="pre">True</span></code> is not needed and often can be worked around in a much
more efficient way. Defaults to the value of <code class="docutils literal notranslate"><span class="pre">create_graph</span></code>.</p></li>
<li><p><strong>create_graph</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, graph of the derivative will be constructed,
allowing to compute higher order derivative products. Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt id="oneflow.autograd.grad">
<code class="sig-prename descclassname"><span class="pre">oneflow.autograd.</span></code><code class="sig-name descname"><span class="pre">grad</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_outputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">create_graph</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> → <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">oneflow._oneflow_internal.Tensor</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#oneflow.autograd.grad" title="Permalink to this definition">¶</a></dt>
<dd><p>The documentation is referenced from:
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.autograd.grad.html#torch.autograd.grad">https://pytorch.org/docs/stable/generated/torch.autograd.grad.html#torch.autograd.grad</a></p>
<p>Computes and returns the sum of gradients of outputs with respect to the inputs.</p>
<p>The graph is differentiated using the chain rule. <code class="docutils literal notranslate"><span class="pre">grad_outputs</span></code> should be a sequence of
length matching <code class="docutils literal notranslate"><span class="pre">outputs</span></code>, containing the “vector” in the Jacobian-vector product.
(<code class="docutils literal notranslate"><span class="pre">None</span></code> is an acceptable value for that tensor don’t require gradient.)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="tensor.html#oneflow.Tensor" title="oneflow.Tensor"><em>Tensor</em></a><em>]</em>) – Tensors of which the derivative will be computed.</p></li>
<li><p><strong>inputs</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="tensor.html#oneflow.Tensor" title="oneflow.Tensor"><em>Tensor</em></a><em>]</em>) – Inputs w.r.t. which the derivative will be returned(and not
accumulated into <code class="docutils literal notranslate"><span class="pre">.grad</span></code>).</p></li>
<li><p><strong>grad_outputs</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="tensor.html#oneflow.Tensor" title="oneflow.Tensor"><em>Tensor</em></a><em>]</em><em>, </em><em>optional</em>) – The “vector” in the Jacobian-vector product.
Usually gradients w.r.t. each output. None values can be specified for scalar Tensors
or ones that don’t require grad. Defaults to None.</p></li>
<li><p><strong>retain_graph</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the graph used to compute the grads will be
reset after backward is complete. Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>. Note that in nearly all cases
setting this option to <code class="docutils literal notranslate"><span class="pre">True</span></code> is not needed and often can be worked around in a much
more efficient way. Defaults to the value of <code class="docutils literal notranslate"><span class="pre">create_graph</span></code>.</p></li>
<li><p><strong>create_graph</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, graph of the derivative will be constructed,
allowing to compute higher order derivative products. Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple of tensors containing the gradients for each <code class="docutils literal notranslate"><span class="pre">inputs</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple(<a class="reference internal" href="tensor.html#oneflow.Tensor" title="oneflow.Tensor">Tensor</a>)</p>
</dd>
</dl>
</dd></dl>
</div>
</div>

      </article>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="cuda.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">oneflow.cuda</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="functional.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">oneflow.nn.functional</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2020, OneFlow
            |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>.
            |
            <a class="muted-link" href="_sources/autograd.rst.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">oneflow.autograd</a><ul>
<li><a class="reference internal" href="#functions-and-classes-for-autograd">Functions and classes for autograd.</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </main>
</div>
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/scripts/main.js?digest=e931d09b2a40c1bb82b542effe772014573baf67"></script></body>
</html>